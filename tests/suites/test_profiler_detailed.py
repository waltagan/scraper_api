import asyncio
import json
import time
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Imports do app
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))

from app.services.llm.llm_service import get_llm_service
from app.core.config import settings

# Constantes de teste
MAX_CONCURRENT_REQUESTS = 300 # Stress test total
TOTAL_SITES_TO_TEST = 300    # Meta: 300 empresas

async def load_test_data() -> List[str]:
    """Carrega dados de relat√≥rios anteriores ou gera dados fake."""
    reports_dir = Path("tests/reports")
    # Tentar pegar os relat√≥rios mais recentes de scraper
    scraper_reports = sorted(list(reports_dir.glob("scraper_test_*.json")), reverse=True)
    
    contents = []
    
    print("üìÇ Buscando dados de scraping anteriores...")
    for report_file in scraper_reports:
        try:
            with open(report_file, 'r') as f:
                data = json.load(f)
                
                # Formato 1: Lista de resultados
                results = data.get('results', [])
                if isinstance(results, dict):
                    results_list = results.values()
                else:
                    results_list = results
                    
                for result in results_list:
                    text = ""
                    # Tenta extrair texto de diferentes formatos poss√≠veis
                    if isinstance(result, list) and len(result) > 0:
                         # Formato (text, docs, links)
                        text = result[0]
                    elif isinstance(result, dict):
                        # Formato ScrapedContent
                        text = result.get('content', '') or result.get('text', '') or result.get('main_content', '')
                        if not text and 'main_page' in result:
                             text = result['main_page'].get('content', '')
                    
                    if text and isinstance(text, str) and len(text) > 500: # Ignorar textos muito curtos
                        contents.append(text)
                        
        except Exception as e:
            # logger.warning(f"Erro ao ler {report_file}: {e}")
            pass
            
        if len(contents) >= TOTAL_SITES_TO_TEST:
            break
            
    print(f"üìä Dados reais encontrados: {len(contents)}")
            
    # Se n√£o tiver dados suficientes, preencher com dados sint√©ticos ou duplicar
    if not contents:
        logger.warning("Nenhum conte√∫do real encontrado, usando dados sint√©ticos.")
        base_text = """
        A TechSolutions √© uma empresa l√≠der em desenvolvimento de software e solu√ß√µes digitais.
        Fundada em 2010, oferecemos servi√ßos de consultoria em TI, desenvolvimento web, aplicativos mobile e cloud computing.
        Nossa miss√£o √© transformar neg√≥cios atrav√©s da tecnologia.
        Atuamos nos setores financeiro, varejo e sa√∫de.
        Nossos principais produtos incluem o TechFlow (plataforma SaaS de gest√£o) e o CyberGuard (solu√ß√£o de seguran√ßa cibern√©tica).
        Temos parcerias estrat√©gicas com AWS, Microsoft e Google.
        A empresa possui certifica√ß√£o ISO 27001 e GPTW (Great Place to Work).
        Contato: contato@techsolutions.com.br | Tel: (11) 3333-4444
        Endere√ßo: Av. Paulista, 1000, 5¬∫ andar, S√£o Paulo - SP.
        CEO: Jo√£o Silva. CTO: Maria Oliveira.
        """
        contents = [base_text for _ in range(TOTAL_SITES_TO_TEST)]
    
    # Completar se faltar (duplicando dados reais para teste de carga)
    original_len = len(contents)
    if original_len > 0:
        while len(contents) < TOTAL_SITES_TO_TEST:
            # Pega um aleat√≥rio ou ciclo
            idx = len(contents) % original_len
            contents.append(contents[idx])
        
    return contents[:TOTAL_SITES_TO_TEST]

async def run_profiler_test():
    """Executa o teste de carga do profiler."""
    print(f"üöÄ Iniciando Teste de Perfil (LLM) - {datetime.now().isoformat()}")
    print(f"üìä Alvo: {TOTAL_SITES_TO_TEST} empresas em paralelo")
    
    # 1. Carregar dados
    contents = await load_test_data()
    print(f"‚úÖ {len(contents)} textos preparados para an√°lise.")
    
    # 2. Preparar LLM Service
    service = get_llm_service()
    providers = service.provider_manager.available_providers
    print(f"ü§ñ Providers dispon√≠veis: {providers}")
    
    # 3. Executar em paralelo
    print("‚ö° Iniciando processamento paralelo...")
    start_time = time.perf_counter()
    
    # Sem√°foro para controlar concorr√™ncia local
    sem = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
    
    results = []
    
    async def analyze_wrapper(index, text):
        async with sem:
            t0 = time.perf_counter()
            try:
                # Simula delay de rede/IO aleat√≥rio antes de chamar LLM para n√£o bater todos exatos no mesmo ms
                await asyncio.sleep(index * 0.01) 
                
                profile = await service.analyze(text)
                duration = time.perf_counter() - t0
                
                # Verifica se houve retorno v√°lido
                has_identity = profile.identity and profile.identity.company_name
                is_success = bool(has_identity or (profile.offerings.products and len(profile.offerings.products) > 0))
                
                return {
                    "index": index,
                    "success": is_success,
                    "duration": duration,
                    "profile_name": profile.identity.company_name if has_identity else "Unknown",
                    "error": None
                }
            except Exception as e:
                duration = time.perf_counter() - t0
                return {
                    "index": index,
                    "success": False,
                    "duration": duration,
                    "profile_name": None,
                    "error": str(e)
                }

    tasks = [analyze_wrapper(i, text) for i, text in enumerate(contents)]
    
    # Barra de progresso
    completed = 0
    total = len(tasks)
    
    # Usar as_completed para monitorar progresso
    for future in asyncio.as_completed(tasks):
        res = await future
        results.append(res)
        completed += 1
        if completed % 10 == 0:
            print(f"   Progresso: {completed}/{total} ({(completed/total)*100:.1f}%) - √öltimo: {res['duration']:.2f}s {'‚úÖ' if res['success'] else '‚ùå'}")
            
    total_time = time.perf_counter() - start_time
    
    # 4. An√°lise de Resultados
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    avg_time = sum(r['duration'] for r in results) / len(results) if results else 0
    
    print("\n" + "="*50)
    print("üèÅ RELAT√ìRIO FINAL DE TESTE (LLM / PERFIL)")
    print("="*50)
    print(f"‚è±Ô∏è Tempo Total de Execu√ß√£o: {total_time:.2f}s")
    print(f"üìâ Tempo M√©dio por Requisi√ß√£o: {avg_time:.2f}s")
    print(f"‚úÖ Sucessos: {len(successful)} ({len(successful)/total*100:.1f}%)")
    print(f"‚ùå Falhas: {len(failed)} ({len(failed)/total*100:.1f}%)")
    print(f"üöÄ Throughput: {(len(results)/total_time)*60:.1f} RPM")
    
    if failed:
        print("\nüîç Principais Erros:")
        errors = {}
        for f in failed:
            msg = f['error'] or "Unknown"
            # Simplificar mensagem de erro
            short_msg = msg[:100]
            errors[short_msg] = errors.get(short_msg, 0) + 1
        for msg, count in errors.items():
            print(f"   - {msg}...: {count}x")
            
    # Salvar relat√≥rio detalhado
    report = {
        "timestamp": datetime.now().isoformat(),
        "config": {
            "total_sites": TOTAL_SITES_TO_TEST,
            "max_concurrent": MAX_CONCURRENT_REQUESTS,
            "providers": providers
        },
        "metrics": {
            "total_time": total_time,
            "success_rate": len(successful)/total,
            "avg_latency": avg_time,
            "throughput_rpm": (len(results) / total_time) * 60
        },
        "details": sorted(results, key=lambda x: x['index'])
    }
    
    report_path = f"tests/reports/profiler_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    os.makedirs("tests/reports", exist_ok=True)
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
        
    print(f"\nüìÑ Relat√≥rio completo salvo em: {report_path}")

if __name__ == "__main__":
    try:
        asyncio.run(run_profiler_test())
    except KeyboardInterrupt:
        print("\nüõë Teste interrompido pelo usu√°rio.")

