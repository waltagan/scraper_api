# PRD - Product Requirements Document
## Sistema de ConstruÃ§Ã£o de Perfis de Empresas B2B - v2.0

**VersÃ£o:** 2.0  
**Data:** 2025-12-05  
**Autor:** AnÃ¡lise TÃ©cnica  
**Status:** Em Desenvolvimento  

---

## ğŸ“‹ SumÃ¡rio Executivo

### Objetivo do Sistema
Construir perfis completos de empresas B2B a partir de dados cadastrais (nome fantasia, razÃ£o social, CNPJ, CNAE, etc.) em atÃ© **90 segundos**, incluindo:
- Descoberta automÃ¡tica do site oficial
- Scraping do site e subpÃ¡ginas
- AnÃ¡lise por LLM para geraÃ§Ã£o de perfil estruturado

> **Nota v2.0**: O mÃ³dulo de extraÃ§Ã£o de documentos (PDFs, DOCs) foi removido desta versÃ£o para simplificar o fluxo e melhorar a performance. A extraÃ§Ã£o de conteÃºdo foca exclusivamente em pÃ¡ginas HTML.

### Problema Atual
O sistema apresenta **falhas estruturais** ao processar 500 empresas consecutivas:
1. **MÃ³dulo de Scraper (71.5% das falhas):** NÃ£o adaptÃ¡vel a diferentes tipos de sites
2. **MÃ³dulo de LLM (19.2% das falhas):** Timeouts e rate limits nÃ£o tratados adequadamente

### Meta
Taxa de sucesso â‰¥ 95% com tempo mÃ©dio de processamento â‰¤ 90 segundos por empresa.

### ğŸ¯ CritÃ©rio de AprovaÃ§Ã£o Final: STRESS TEST

O sistema serÃ¡ considerado **APROVADO** quando passar no seguinte teste:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STRESS TEST - CRITÃ‰RIO DE APROVAÃ‡ÃƒO                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ“Š PARÃ‚METROS DO TESTE:                                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  â€¢ Empresas processadas: 500 em paralelo                                    â”‚
â”‚  â€¢ Timeout por empresa: 90 segundos                                         â”‚
â”‚  â€¢ Fonte de dados: Lista real de empresas brasileiras (CNPJ vÃ¡lidos)        â”‚
â”‚                                                                             â”‚
â”‚  âœ… CRITÃ‰RIOS DE SUCESSO:                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  1. Tempo mÃ©dio â‰¤ 90s (apenas empresas COM site encontrado)                 â”‚
â”‚  2. Taxa de sucesso â‰¥ 90% (das empresas COM site encontrado)                â”‚
â”‚  3. Completude do perfil â‰¥ 85% (campos obrigatÃ³rios preenchidos)            â”‚
â”‚  4. Zero crashes/memory leaks durante execuÃ§Ã£o                              â”‚
â”‚  5. Todos os LLM providers funcionando (fallback operacional)               â”‚
â”‚                                                                             â”‚
â”‚  âŒ EMPRESAS DESCARTADAS (nÃ£o contam nas mÃ©tricas):                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”‚
â”‚  â€¢ Site oficial nÃ£o encontrado pelo Discovery                               â”‚
â”‚  â€¢ Site fora do ar / domÃ­nio expirado                                       â”‚
â”‚  â€¢ Site bloqueado geograficamente                                           â”‚
â”‚                                                                             â”‚
â”‚  âš ï¸ PRESERVAÃ‡ÃƒO DA QUALIDADE:                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  â€¢ NÃƒO reduzir nÃºmero de subpÃ¡ginas scraped                                 â”‚
â”‚  â€¢ NÃƒO reduzir campos extraÃ­dos pelo LLM                                    â”‚
â”‚  â€¢ NÃƒO simplificar prompts para acelerar                                    â”‚
â”‚  â€¢ MANTER extraÃ§Ã£o completa de todas as seÃ§Ãµes do perfil                    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Importante:** A qualidade dos perfis Ã© **INEGOCIÃVEL**. OtimizaÃ§Ãµes de performance NÃƒO podem sacrificar a completude dos dados extraÃ­dos.

### DecisÃµes de Arquitetura v2.0

#### âŒ RemoÃ§Ã£o do MÃ³dulo de Documentos (PDF/DOC)

**Motivo da RemoÃ§Ã£o:**
1. **Complexidade adicional**: O download e parsing de documentos adiciona latÃªncia significativa (5-15s por documento)
2. **Taxa de sucesso baixa**: Muitos PDFs estÃ£o protegidos, corrompidos ou sÃ£o muito grandes
3. **Valor marginal**: A maioria das informaÃ§Ãµes relevantes jÃ¡ estÃ¡ disponÃ­vel nas pÃ¡ginas HTML
4. **SimplificaÃ§Ã£o do fluxo**: Menos pontos de falha = maior confiabilidade

**Impacto Esperado:**
- â¬‡ï¸ Tempo mÃ©dio de processamento: -10s a -30s
- â¬†ï¸ Taxa de sucesso: +5% a +10%
- â¬‡ï¸ Complexidade do cÃ³digo: -30%

**Alternativa Futura:**
Se necessÃ¡rio, o mÃ³dulo de documentos pode ser reimplementado como um serviÃ§o separado, acionado sob demanda apÃ³s a anÃ¡lise inicial do perfil.

#### âš ï¸ RestriÃ§Ãµes de Recursos do Servidor

**Contexto:** O servidor de produÃ§Ã£o possui recursos limitados de memÃ³ria e CPU. SoluÃ§Ãµes que exigem muitos recursos devem ser evitadas.

**SoluÃ§Ãµes PROIBIDAS (alto consumo de memÃ³ria):**

| SoluÃ§Ã£o | Consumo de MemÃ³ria | Motivo da ProibiÃ§Ã£o |
|---------|-------------------|---------------------|
| ğŸš« Playwright | ~300-500MB/instÃ¢ncia | Browser completo em memÃ³ria |
| ğŸš« Undetected Chrome | ~500MB+/instÃ¢ncia | Chrome real + patches anti-detecÃ§Ã£o |
| ğŸš« Selenium | ~400MB+/instÃ¢ncia | Browser completo + driver |
| ğŸš« Puppeteer | ~300-500MB/instÃ¢ncia | Similar ao Playwright |

**SoluÃ§Ãµes APROVADAS (baixo consumo de memÃ³ria):**

| SoluÃ§Ã£o | Consumo de MemÃ³ria | Uso Recomendado |
|---------|-------------------|-----------------|
| âœ… curl_cffi | ~5-10MB | Scraping principal (simula TLS fingerprint) |
| âœ… System Curl | ~2-5MB | Fallback para sites simples |
| âœ… httpx/aiohttp | ~10-20MB | RequisiÃ§Ãµes HTTP simples |
| âœ… BeautifulSoup | ~20-50MB | Parsing de HTML |

**PrincÃ­pio:** Sempre priorizar soluÃ§Ãµes baseadas em HTTP puro. Browsers headless sÃ£o **ÃšLTIMO RECURSO** e devem ser usados via serviÃ§o externo (ex: API de scraping terceirizada), nunca no servidor principal.

---

## ğŸ“Š DiagnÃ³stico do Estado Atual

### Arquitetura Atual (v1.0)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              API FastAPI                                     â”‚
â”‚                            /analyze endpoint                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Discovery   â”‚â”€â”€â”€â–¶â”‚   Scraper    â”‚â”€â”€â”€â–¶â”‚     PDF      â”‚â”€â”€â”€â–¶â”‚    LLM    â”‚ â”‚
â”‚  â”‚  (Google)    â”‚    â”‚  (curl_cffi) â”‚    â”‚  (PyMuPDF)   â”‚    â”‚  (Gemini/ â”‚ â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚  âŒ REMOVIDO â”‚    â”‚   OpenAI) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â–²                    â–²                                       â”‚      â”‚
â”‚        â”‚                    â”‚                                       â–¼      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚   Serper     â”‚    â”‚    Proxy     â”‚                      â”‚CompanyProfile â”‚
â”‚  â”‚     API      â”‚    â”‚   Manager    â”‚                      â”‚    (JSON)     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Arquitetura v2.0 (Simplificada - sem mÃ³dulo PDF)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              API FastAPI                                     â”‚
â”‚                            /analyze endpoint                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  Discovery   â”‚â”€â”€â”€â–¶â”‚   Scraper    â”‚â”€â”€â”€â–¶â”‚    LLM    â”‚                     â”‚
â”‚  â”‚  (Serper)    â”‚    â”‚  (curl_cffi) â”‚    â”‚  (Gemini/ â”‚                     â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚   OpenAI) â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚        â–²                    â–²                  â”‚                            â”‚
â”‚        â”‚                    â”‚                  â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚   Cache      â”‚    â”‚    Proxy     â”‚   â”‚CompanyProfile â”‚                  â”‚
â”‚  â”‚   Domains    â”‚    â”‚   Manager    â”‚   â”‚    (JSON)     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MÃ©tricas de Falha (AnÃ¡lise de Logs)

| Categoria | Quantidade | % do Total | Causa Principal |
|-----------|------------|------------|-----------------|
| ğŸ“­ Empty Content | 693 | 71.5% | Cloudflare, WAF, SPA |
| â±ï¸ Timeout | 186 | 19.2% | Proxy lento, rate limit |
| â“ HTTP 404 | 24 | 2.5% | Links quebrados |
| â” Outros | 66 | 6.8% | Diversos |

### Testes de ValidaÃ§Ã£o Realizados

| MÃ©todo | Taxa de Sucesso (sem proxy) | Taxa de Sucesso (com proxy) |
|--------|-----------------------------|-----------------------------|
| curl_cffi | **100%** âœ… | 85% |
| System Curl | 31% | 28% |

**ConclusÃ£o:** O problema principal estÃ¡ na **latÃªncia do proxy** e na **detecÃ§Ã£o de proteÃ§Ãµes anti-bot**.

---

## ğŸ¯ Requisitos Funcionais

### RF01 - Scraper Adaptativo (Leve)
O sistema deve identificar automaticamente o tipo de site e adaptar a estratÃ©gia de scraping, **usando apenas soluÃ§Ãµes baseadas em HTTP** (sem browser headless).

**CritÃ©rios de Aceite:**
- [ ] Detectar presenÃ§a de Cloudflare em < 2 segundos
- [ ] Detectar sites SPA/JavaScript-heavy e marcar como "conteÃºdo limitado"
- [ ] Tentar mÃºltiplas variaÃ§Ãµes de acesso (https/http, www/sem-www)
- [ ] Fallback automÃ¡tico entre mÃ©todos de scrape (FAST â†’ STANDARD â†’ ROBUST â†’ AGGRESSIVE)
- [ ] NÃ£o contar proteÃ§Ãµes anti-bot como falhas no circuit breaker
- [ ] **NÃƒO usar** Playwright, Selenium ou qualquer browser headless

**Tratamento de Sites SPA:**
- Sites que requerem JavaScript para renderizar conteÃºdo serÃ£o marcados com flag `requer_js=True`
- O conteÃºdo extraÃ­do pode ser limitado (apenas HTML estÃ¡tico)
- Isso Ã© aceitÃ¡vel - muitos sites tÃªm informaÃ§Ãµes bÃ¡sicas no HTML estÃ¡tico (meta tags, texto inicial)
- Se o conteÃºdo for insuficiente, o perfil serÃ¡ marcado como "parcial"

### RF02 - GestÃ£o Inteligente de LLM
O sistema deve gerenciar mÃºltiplos provedores de LLM com balanceamento de carga real.

**CritÃ©rios de Aceite:**
- [ ] Suportar 3+ provedores de LLM (Google, OpenAI, OpenRouter)
- [ ] Failover automÃ¡tico em caso de rate limit
- [ ] Retry com backoff exponencial
- [ ] Queue management para evitar burst de requisiÃ§Ãµes
- [ ] Monitoramento de saÃºde em tempo real

### RF03 - Sistema de Auto-Aprendizado
O sistema deve aprender com falhas e melhorar automaticamente.

**CritÃ©rios de Aceite:**
- [ ] Registrar todas as falhas com contexto completo
- [ ] Categorizar falhas automaticamente
- [ ] Sugerir melhorias baseadas em padrÃµes de falha
- [ ] Manter base de conhecimento de sites problemÃ¡ticos
- [ ] Atualizar configuraÃ§Ãµes dinamicamente

### RF04 - Testes Automatizados por MÃ³dulo
Cada mÃ³dulo deve ter suite de testes independente.

**CritÃ©rios de Aceite:**
- [ ] Test suite para Scraper com 500+ sites
- [ ] Test suite para LLM com 300+ scrapes
- [ ] MÃ©tricas de performance por teste
- [ ] RelatÃ³rios automatizados de regressÃ£o

---

## ğŸ—ï¸ Arquitetura Proposta v2.0

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    API FastAPI                                           â”‚
â”‚                                  /analyze endpoint                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                           ğŸ§  ORCHESTRATOR INTELIGENTE                               â”‚â”‚
â”‚  â”‚    â€¢ Timeout global configurÃ¡vel (90s padrÃ£o)                                       â”‚â”‚
â”‚  â”‚    â€¢ Retry manager centralizado                                                     â”‚â”‚
â”‚  â”‚    â€¢ MÃ©tricas e telemetria                                                          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                          â”‚                                              â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚       â”‚                                  â”‚                                  â”‚          â”‚
â”‚       â–¼                                  â–¼                                  â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Discovery   â”‚                 â”‚   Scraper    â”‚                 â”‚     LLM      â”‚    â”‚
â”‚  â”‚   Service    â”‚                 â”‚   Service    â”‚                 â”‚   Service    â”‚    â”‚
â”‚  â”‚              â”‚                 â”‚              â”‚                 â”‚              â”‚    â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚ â”‚  Serper  â”‚ â”‚                 â”‚ â”‚ Detector â”‚ â”‚                 â”‚ â”‚ Balancer â”‚ â”‚    â”‚
â”‚  â”‚ â”‚   API    â”‚ â”‚                 â”‚ â”‚   WAF    â”‚ â”‚                 â”‚ â”‚  v2.0    â”‚ â”‚    â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â”‚              â”‚                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                 â”‚ â”‚ Strategy â”‚ â”‚                 â”‚ â”‚  Queue   â”‚ â”‚    â”‚
â”‚  â”‚ â”‚  Cache   â”‚ â”‚                 â”‚ â”‚ Selector â”‚ â”‚                 â”‚ â”‚ Manager  â”‚ â”‚    â”‚
â”‚  â”‚ â”‚ Domains  â”‚ â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚ â”‚ Parallel â”‚ â”‚                 â”‚ â”‚ Provider â”‚ â”‚    â”‚
â”‚                                   â”‚ â”‚  Scraper â”‚ â”‚                 â”‚ â”‚  Pool    â”‚ â”‚    â”‚
â”‚                                   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                          â”‚                                  â”‚          â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚       â”‚                                  â”‚                                              â”‚
â”‚       â–¼                                  â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                        ğŸ“Š LEARNING ENGINE (NOVO)                              â”‚      â”‚
â”‚  â”‚                                                                               â”‚      â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚      â”‚
â”‚  â”‚   â”‚  Failure   â”‚   â”‚  Pattern   â”‚   â”‚   Config   â”‚   â”‚  Metrics   â”‚         â”‚      â”‚
â”‚  â”‚   â”‚  Tracker   â”‚   â”‚  Analyzer  â”‚   â”‚  Optimizer â”‚   â”‚  Reporter  â”‚         â”‚      â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚      â”‚
â”‚  â”‚                                                                               â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ MÃ³dulo 1: Scraper Adaptativo v2.0

### 1.1 Problema Atual
- Timeout fixo de 15s nÃ£o adequado para todos os sites
- NÃ£o detecta tipo de proteÃ§Ã£o antes de tentar scrape
- Circuit breaker muito agressivo (threshold = 5)
- NÃ£o tenta variaÃ§Ãµes de URL (http/https, www/non-www)

### 1.2 SoluÃ§Ã£o Proposta

#### 1.2.1 Site Analyzer (PrÃ©-Scrape)
```python
class SiteAnalyzer:
    """
    Analisa caracterÃ­sticas do site ANTES do scrape completo.
    Tempo alvo: < 3 segundos
    Usa apenas requisiÃ§Ãµes HTTP leves (sem browser).
    """
    
    async def analyze(self, url: str) -> SiteProfile:
        """
        Retorna:
        - tipo_protecao: cloudflare | waf | captcha | none
        - tipo_site: spa | static | hybrid
        - tempo_resposta: latÃªncia mÃ©dia
        - melhor_metodo: cffi | curl | cffi_aggressive
        - variacoes_validas: lista de URLs que respondem
        - requer_js: bool (se True, site pode ter conteÃºdo limitado)
        """
```

#### 1.2.2 Strategy Selector
```python
class ScrapingStrategy(Enum):
    """
    EstratÃ©gias de scraping LEVES (sem browser headless).
    Todas as estratÃ©gias usam curl_cffi ou system curl para economia de recursos.
    """
    FAST = "fast"              # curl_cffi sem proxy, timeout 10s
    STANDARD = "standard"      # curl_cffi com proxy, timeout 15s
    ROBUST = "robust"          # System curl com retry, timeout 20s
    AGGRESSIVE = "aggressive"  # curl_cffi com mÃºltiplos user-agents e rotaÃ§Ã£o de proxy
    
    # âŒ REMOVIDO: HEADLESS (Playwright) - Alto consumo de memÃ³ria
    # âŒ REMOVIDO: STEALTH (Undetected Chrome) - Alto consumo de memÃ³ria

class StrategySelector:
    """
    Seleciona estratÃ©gia baseada no SiteProfile.
    Prioriza sempre estratÃ©gias leves (curl-based).
    """
    def select(self, profile: SiteProfile) -> List[ScrapingStrategy]:
        # Retorna lista ordenada por prioridade
        # Para sites com Cloudflare: tenta AGGRESSIVE primeiro, depois ROBUST
        # Para sites normais: FAST -> STANDARD -> ROBUST
```

#### 1.2.3 Parallel URL Prober
```python
async def probe_url_variations(base_url: str) -> BestURLResult:
    """
    Testa em paralelo todas as variaÃ§Ãµes de uma URL.
    
    VariaÃ§Ãµes testadas:
    - https://www.domain.com
    - https://domain.com
    - http://www.domain.com
    - http://domain.com
    
    Retorna a primeira que responder com sucesso.
    Timeout por variaÃ§Ã£o: 3s
    """
```

#### 1.2.4 Protection Detector
```python
class ProtectionDetector:
    """
    Detecta tipo de proteÃ§Ã£o anti-bot rapidamente.
    """
    
    CLOUDFLARE_SIGNATURES = [
        "cf-browser-verification",
        "cf_chl_opt",
        "checking your browser",
        "just a moment...",
        "ray id:",
        "__cf_bm"  # Cookie Cloudflare
    ]
    
    WAF_SIGNATURES = [
        "access denied",
        "403 forbidden",
        "blocked by security",
        "firewall"
    ]
    
    CAPTCHA_SIGNATURES = [
        "recaptcha",
        "hcaptcha",
        "challenge-form",
        "g-recaptcha"
    ]
    
    async def detect(self, response: Response) -> ProtectionType:
        # Analisa headers e conteÃºdo
        # Retorna: CLOUDFLARE | WAF | CAPTCHA | RATE_LIMIT | NONE
```

### 1.3 ConfiguraÃ§Ãµes Propostas

```python
SCRAPER_CONFIG_V2 = {
    # Timeouts escalonados por estratÃ©gia (todas curl-based, sem browser)
    'fast_timeout': 10,
    'standard_timeout': 15,
    'robust_timeout': 20,
    'aggressive_timeout': 25,  # Para sites com proteÃ§Ã£o (mais retries)
    
    # Circuit Breaker inteligente
    'circuit_breaker_threshold': 10,  # Aumentado de 5
    'circuit_breaker_exclude_protections': True,  # NÃ£o contar Cloudflare
    'circuit_breaker_reset_after': 300,  # Reset apÃ³s 5 min
    
    # Paralelismo (ajustado para servidor com recursos limitados)
    'max_concurrent_probes': 4,
    'max_concurrent_subpages': 15,  # Reduzido de 20
    'chunk_size': 8,  # Reduzido de 10 para economia de memÃ³ria
    
    # Proxy
    'proxy_rotation_on_failure': True,
    'max_proxy_retries': 3,
    
    # Adaptativo
    'auto_adjust_timeout': True,
    'learn_from_failures': True,
    
    # User-Agent Rotation (para estratÃ©gia AGGRESSIVE)
    'rotate_user_agent': True,
    'user_agent_pool_size': 10
}
```

### 1.4 Fluxo de Scrape Adaptativo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   URL Entrada   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. PROBE PARALELO (3s max)    â”‚
â”‚   - Testar https/http           â”‚
â”‚   - Testar www/non-www          â”‚
â”‚   - Medir latÃªncia              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   2. DETECTAR PROTEÃ‡ÃƒO (2s)     â”‚
â”‚   - Verificar Cloudflare        â”‚
â”‚   - Verificar WAF               â”‚
â”‚   - Verificar Captcha           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚
     â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NONE   â”‚   â”‚ CLOUDFLARE/WAF  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚
     â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FAST   â”‚   â”‚   AGGRESSIVE    â”‚
â”‚ STRATEGYâ”‚   â”‚   STRATEGY      â”‚
â”‚(curl_cffi)â”‚ â”‚(curl_cffi + UA  â”‚
â”‚          â”‚  â”‚ rotation + proxy)â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   3. SCRAPE MAIN PAGE           â”‚
â”‚   - Usar estratÃ©gia selecionada â”‚
â”‚   - Timeout adaptativo          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚
     â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SUCESSO â”‚   â”‚     FALHA       â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚
     â”‚                â–¼
     â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚        â”‚ FALLBACK p/     â”‚
     â”‚        â”‚ prÃ³xima strategyâ”‚
     â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   4. SELECIONAR SUBPÃGINAS      â”‚
â”‚   - LLM escolhe top N relevantesâ”‚
â”‚   - MÃ¡x 30 subpÃ¡ginas           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   5. SCRAPE PARALELO SUBPÃGINAS â”‚
â”‚   - Chunks de 10                â”‚
â”‚   - Mesma estratÃ©gia que main   â”‚
â”‚   - Circuit breaker por domÃ­nio â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   6. CONSOLIDAR CONTEÃšDO        â”‚
â”‚   - Remover duplicados          â”‚
â”‚   - Ordenar por relevÃ¢ncia      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ MÃ³dulo 2: LLM Manager v2.0

### 2.1 Problema Atual
- Apenas 2 provedores configurados (Google Gemini, OpenAI)
- SemÃ¡foros com limites muito altos (300/250) nÃ£o respeitando rate limits reais
- Round-robin simples nÃ£o considera saÃºde do provedor
- Timeout fixo de 90s pode ser excessivo para modelos rÃ¡pidos

### 2.2 SoluÃ§Ã£o Proposta

#### 2.2.1 Adicionar OpenRouter como Fallback
```python
# Novos provedores no config.py
OPENROUTER_API_KEY: str = os.getenv("OPENROUTER_API_KEY", "")
OPENROUTER_BASE_URL: str = "https://openrouter.ai/api/v1"
OPENROUTER_MODEL: str = "google/gemini-2.0-flash-exp:free"  # Modelo gratuito

# Ordem de prioridade:
# 1. Google Gemini (mais rÃ¡pido, rate limit generoso)
# 2. OpenAI (confiÃ¡vel, rate limit mÃ©dio)  
# 3. OpenRouter (fallback, mÃºltiplos modelos)
```

#### 2.2.2 Queue Manager com Rate Limiting Real
```python
class LLMQueueManager:
    """
    Gerencia fila de requisiÃ§Ãµes respeitando rate limits reais.
    """
    
    # Rate limits por provedor (tokens por minuto)
    RATE_LIMITS = {
        "Google Gemini": {"tpm": 4_000_000, "rpm": 1500},
        "OpenAI": {"tpm": 2_000_000, "rpm": 500},
        "OpenRouter": {"tpm": 100_000, "rpm": 100}
    }
    
    def __init__(self):
        self.queues = {name: asyncio.Queue() for name in RATE_LIMITS}
        self.token_buckets = {
            name: TokenBucket(limits["tpm"], limits["rpm"]) 
            for name, limits in RATE_LIMITS.items()
        }
    
    async def enqueue(self, request: LLMRequest) -> LLMResponse:
        """
        Enfileira requisiÃ§Ã£o e aguarda slot disponÃ­vel.
        Usa token bucket para controle de rate limit.
        """
        
    async def get_best_provider(self, estimated_tokens: int) -> str:
        """
        Retorna provedor com capacidade disponÃ­vel.
        Considera:
        - Tokens disponÃ­veis no bucket
        - LatÃªncia mÃ©dia recente
        - Taxa de sucesso
        """
```

#### 2.2.3 Health Monitor Aprimorado
```python
class LLMHealthMonitor:
    """
    Monitora saÃºde dos provedores em tempo real.
    """
    
    def __init__(self):
        self.metrics = defaultdict(lambda: {
            "requests_total": 0,
            "requests_success": 0,
            "requests_failed": 0,
            "rate_limits_hit": 0,
            "timeouts": 0,
            "avg_latency_ms": 0,
            "last_success": None,
            "last_failure": None,
            "consecutive_failures": 0,
            "health_score": 100  # 0-100
        })
    
    def update_health_score(self, provider: str):
        """
        Calcula score de saÃºde (0-100) baseado em:
        - Taxa de sucesso (peso 40%)
        - LatÃªncia (peso 30%)
        - Rate limits (peso 20%)
        - RecÃªncia de falhas (peso 10%)
        """
    
    def get_healthy_providers(self) -> List[Tuple[str, int]]:
        """
        Retorna provedores ordenados por health_score.
        Exclui provedores com score < 20.
        """
```

#### 2.2.4 Adaptive Timeout
```python
class AdaptiveTimeout:
    """
    Ajusta timeout baseado em histÃ³rico de latÃªncia.
    """
    
    def __init__(self):
        self.latency_history = defaultdict(lambda: deque(maxlen=100))
    
    def get_timeout(self, provider: str, content_size: int) -> float:
        """
        Calcula timeout ideal baseado em:
        - P95 de latÃªncia histÃ³rica
        - Tamanho do conteÃºdo
        - Modelo especÃ­fico
        
        FÃ³rmula: max(30, p95_latency * 1.5 + (content_size / 10000) * 5)
        """
```

### 2.3 ConfiguraÃ§Ãµes Propostas

```python
LLM_CONFIG_V2 = {
    # Provedores (ordem de prioridade)
    'providers': [
        {
            'name': 'Google Gemini',
            'api_key_env': 'GOOGLE_API_KEY',
            'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/',
            'model': 'gemini-2.0-flash',
            'max_concurrent': 50,  # Reduzido de 300
            'rate_limit_rpm': 1500,
            'rate_limit_tpm': 4_000_000,
            'priority': 1
        },
        {
            'name': 'OpenAI',
            'api_key_env': 'OPENAI_API_KEY', 
            'base_url': 'https://api.openai.com/v1',
            'model': 'gpt-4o-mini',
            'max_concurrent': 30,  # Reduzido de 250
            'rate_limit_rpm': 500,
            'rate_limit_tpm': 2_000_000,
            'priority': 2
        },
        {
            'name': 'OpenRouter',
            'api_key_env': 'OPENROUTER_API_KEY',
            'base_url': 'https://openrouter.ai/api/v1',
            'model': 'google/gemini-2.0-flash-exp:free',
            'max_concurrent': 10,
            'rate_limit_rpm': 100,
            'rate_limit_tpm': 100_000,
            'priority': 3
        }
    ],
    
    # Retry
    'max_retries_per_provider': 2,
    'max_total_retries': 5,
    'retry_backoff_base': 2,
    'retry_backoff_max': 30,
    
    # Timeout
    'base_timeout': 60,
    'max_timeout': 120,
    'adaptive_timeout': True,
    
    # Chunking
    'max_chunk_tokens': 500_000,  # Reduzido de 800k para margem de seguranÃ§a
    'group_target_tokens': 15_000,  # Reduzido de 20k
    
    # Health
    'health_check_interval': 10,
    'unhealthy_threshold': 20,
    'recovery_threshold': 50
}
```

### 2.4 Fluxo de RequisiÃ§Ã£o LLM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ConteÃºdo para AnÃ¡lise        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. ESTIMAR TOKENS             â”‚
â”‚   - Contar caracteres           â”‚
â”‚   - Aplicar fator PT-BR (3.5)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   2. CHUNKING (se necessÃ¡rio)   â”‚
â”‚   - Dividir por pÃ¡ginas         â”‚
â”‚   - Agrupar pequenas pÃ¡ginas    â”‚
â”‚   - Max 500k tokens/chunk       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   3. SELECIONAR PROVEDOR        â”‚
â”‚   - Verificar health_score      â”‚
â”‚   - Verificar rate limit bucket â”‚
â”‚   - Round-robin entre saudÃ¡veis â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚
     â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚DISPONÃVELâ”‚   â”‚ TODOS OCUPADOS  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚
     â”‚                â–¼
     â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚        â”‚ AGUARDAR FILA   â”‚
     â”‚        â”‚ (max 30s)       â”‚
     â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   4. ENVIAR REQUISIÃ‡ÃƒO          â”‚
â”‚   - Timeout adaptativo          â”‚
â”‚   - Registrar mÃ©tricas          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚
     â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SUCESSO â”‚   â”‚     FALHA       â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚
     â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
     â”‚        â”‚               â”‚
     â”‚        â–¼               â–¼
     â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   â”‚RATE LIMITâ”‚   â”‚ TIMEOUT/  â”‚
     â”‚   â”‚         â”‚   â”‚  ERROR    â”‚
     â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚        â”‚              â”‚
     â”‚        â–¼              â–¼
     â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   â”‚ RETRY COM OUTRO PROVIDERâ”‚
     â”‚   â”‚ (atÃ© max_total_retries) â”‚
     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   5. PROCESSAR RESPOSTA         â”‚
â”‚   - Validar JSON                â”‚
â”‚   - Normalizar campos           â”‚
â”‚   - Construir CompanyProfile    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   6. MERGE (se mÃºltiplos chunks)â”‚
â”‚   - Consolidar perfis           â”‚
â”‚   - Remover duplicatas          â”‚
â”‚   - Priorizar dados completos   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ MÃ³dulo 3: Learning Engine (NOVO)

### 3.1 Objetivo
Criar um sistema que aprende com falhas e melhora automaticamente a performance.

### 3.2 Componentes

#### 3.2.1 Failure Tracker
```python
class FailureTracker:
    """
    Registra todas as falhas com contexto completo.
    """
    
    def record_failure(self, failure: FailureRecord):
        """
        Salva em banco de dados:
        - timestamp
        - mÃ³dulo (scraper/llm/discovery)
        - tipo_erro
        - url/domÃ­nio
        - contexto (headers, response, etc)
        - stack_trace
        - configuraÃ§Ã£o_usada
        - tentativas_anteriores
        """
    
    def get_failures_by_domain(self, domain: str) -> List[FailureRecord]:
        """HistÃ³rico de falhas de um domÃ­nio."""
    
    def get_failure_patterns(self, period: str = "24h") -> Dict[str, int]:
        """Agrupa falhas por tipo no perÃ­odo."""
```

#### 3.2.2 Pattern Analyzer
```python
class PatternAnalyzer:
    """
    Analisa padrÃµes de falha e identifica causas raiz.
    """
    
    def analyze_scraper_failures(self) -> ScraperAnalysis:
        """
        Retorna:
        - sites_com_cloudflare: List[str]
        - sites_com_captcha: List[str]
        - sites_timeout_frequente: List[str]
        - melhor_estrategia_por_site: Dict[str, ScrapingStrategy]
        - recomendacoes: List[str]
        """
    
    def analyze_llm_failures(self) -> LLMAnalysis:
        """
        Retorna:
        - provedor_mais_estavel: str
        - horarios_com_mais_rate_limit: List[int]
        - tamanho_chunk_ideal: int
        - modelo_mais_preciso: str
        - recomendacoes: List[str]
        """
```

#### 3.2.3 Config Optimizer
```python
class ConfigOptimizer:
    """
    Otimiza configuraÃ§Ãµes baseado em anÃ¡lise de falhas.
    """
    
    def suggest_scraper_config(self, analysis: ScraperAnalysis) -> Dict:
        """
        Sugere ajustes de configuraÃ§Ã£o do scraper:
        - timeout ideal por tipo de site
        - threshold do circuit breaker
        - estratÃ©gia padrÃ£o
        """
    
    def suggest_llm_config(self, analysis: LLMAnalysis) -> Dict:
        """
        Sugere ajustes de configuraÃ§Ã£o do LLM:
        - limites de semÃ¡foro por provedor
        - tamanho de chunk
        - timeout por modelo
        """
    
    def apply_suggestions(self, suggestions: Dict, auto_apply: bool = False):
        """
        Aplica sugestÃµes automaticamente ou gera relatÃ³rio para review.
        """
```

#### 3.2.4 Site Knowledge Base
```python
class SiteKnowledgeBase:
    """
    Base de conhecimento sobre sites especÃ­ficos.
    """
    
    def add_site_profile(self, profile: SiteKnowledgeProfile):
        """
        Armazena:
        - domÃ­nio
        - tipo_protecao
        - melhor_estrategia
        - tempo_medio_resposta
        - ultima_tentativa_sucesso
        - configuracao_especial (se houver)
        """
    
    def get_site_profile(self, domain: str) -> Optional[SiteKnowledgeProfile]:
        """Retorna perfil se existir."""
    
    def get_strategy_for_site(self, domain: str) -> ScrapingStrategy:
        """
        Retorna melhor estratÃ©gia baseada em histÃ³rico.
        Se nÃ£o houver histÃ³rico, retorna STANDARD.
        """
```

### 3.3 Fluxo de Aprendizado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CICLO DE APRENDIZADO CONTÃNUO                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                         â”‚
â”‚  â”‚  REQUISIÃ‡ÃƒO   â”‚                                                         â”‚
â”‚  â”‚   NORMAL      â”‚                                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                         â”‚
â”‚          â”‚                                                                  â”‚
â”‚          â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      PROCESSAMENTO                                     â”‚ â”‚
â”‚  â”‚                                                                        â”‚ â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚ â”‚
â”‚  â”‚    â”‚  Discovery  â”‚â”€â”€â–¶â”‚   Scraper   â”‚â”€â”€â–¶â”‚     LLM     â”‚               â”‚ â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ â”‚
â”‚  â”‚           â”‚                â”‚                  â”‚                       â”‚ â”‚
â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚ â”‚
â”‚  â”‚                            â”‚                                           â”‚ â”‚
â”‚  â”‚                            â–¼                                           â”‚ â”‚
â”‚  â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚ â”‚
â”‚  â”‚                    â”‚   RESULTADO   â”‚                                  â”‚ â”‚
â”‚  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚ â”‚
â”‚  â”‚                            â”‚                                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                               â”‚                                             â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚          â”‚                    â”‚                    â”‚                       â”‚
â”‚          â–¼                    â–¼                    â–¼                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚   SUCESSO   â”‚     â”‚    FALHA    â”‚     â”‚  PARCIAL    â”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚          â”‚                   â”‚                    â”‚                        â”‚
â”‚          â–¼                   â–¼                    â–¼                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                       FAILURE TRACKER                                â”‚ â”‚
â”‚   â”‚   â€¢ Registrar resultado                                              â”‚ â”‚
â”‚   â”‚   â€¢ Coletar mÃ©tricas                                                 â”‚ â”‚
â”‚   â”‚   â€¢ Armazenar contexto                                               â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                               â”‚                                             â”‚
â”‚                               â–¼                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                      PATTERN ANALYZER                                â”‚ â”‚
â”‚   â”‚   â€¢ Executar a cada 100 requisiÃ§Ãµes                                  â”‚ â”‚
â”‚   â”‚   â€¢ Identificar padrÃµes de falha                                     â”‚ â”‚
â”‚   â”‚   â€¢ Calcular estatÃ­sticas                                            â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                               â”‚                                             â”‚
â”‚                               â–¼                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                      CONFIG OPTIMIZER                                â”‚ â”‚
â”‚   â”‚   â€¢ Gerar sugestÃµes de otimizaÃ§Ã£o                                    â”‚ â”‚
â”‚   â”‚   â€¢ Validar contra thresholds                                        â”‚ â”‚
â”‚   â”‚   â€¢ Aplicar automaticamente (se habilitado)                          â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                               â”‚                                             â”‚
â”‚                               â–¼                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                    SITE KNOWLEDGE BASE                               â”‚ â”‚
â”‚   â”‚   â€¢ Atualizar perfil do site                                         â”‚ â”‚
â”‚   â”‚   â€¢ Armazenar estratÃ©gia bem-sucedida                                â”‚ â”‚
â”‚   â”‚   â€¢ Marcar sites problemÃ¡ticos                                       â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª MÃ³dulo 4: Sistema de Testes Automatizados

### 4.1 Objetivo
Criar testes que validem cada mÃ³dulo isoladamente e em conjunto, com capacidade de identificar regressÃµes.

### 4.2 Test Suites

#### 4.2.1 Scraper Test Suite (500 sites)

```python
# tests/test_scraper_suite.py

class ScraperTestSuite:
    """
    Suite de testes para o mÃ³dulo de scraping.
    Deve ser executada semanalmente ou antes de cada deploy.
    """
    
    # Categorias de sites para teste
    TEST_SITES = {
        "static_simple": [
            # 100 sites estÃ¡ticos simples
        ],
        "static_complex": [
            # 100 sites estÃ¡ticos com muitas subpÃ¡ginas
        ],
        "spa_react": [
            # 50 sites React/Next.js
        ],
        "spa_vue": [
            # 50 sites Vue.js
        ],
        "cloudflare_protected": [
            # 50 sites com Cloudflare
        ],
        "waf_protected": [
            # 50 sites com WAF
        ],
        "slow_response": [
            # 50 sites com resposta > 5s
        ],
        "international": [
            # 50 sites internacionais
        ]
    }
    
    async def run_full_suite(self) -> TestReport:
        """
        Executa todos os testes e gera relatÃ³rio.
        
        MÃ©tricas coletadas por site:
        - tempo_total
        - tempo_main_page
        - tempo_subpages
        - chars_extraidos
        - links_encontrados
        - estrategia_usada
        - protecao_detectada
        - sucesso (bool)
        - erro (se houver)
        """
    
    async def test_single_category(self, category: str) -> CategoryReport:
        """Testa apenas uma categoria de sites."""
    
    def compare_with_baseline(self, report: TestReport) -> ComparisonReport:
        """
        Compara resultados com baseline anterior.
        Identifica regressÃµes (> 5% queda na taxa de sucesso).
        """
    
    def generate_recommendations(self, report: TestReport) -> List[str]:
        """
        Gera recomendaÃ§Ãµes baseadas nos resultados:
        - Sites que precisam de estratÃ©gia especÃ­fica
        - ConfiguraÃ§Ãµes que podem ser otimizadas
        - Bugs identificados
        """
```

#### 4.2.2 LLM Test Suite (300 scrapes)

```python
# tests/test_llm_suite.py

class LLMTestSuite:
    """
    Suite de testes para o mÃ³dulo de LLM.
    Usa conteÃºdo prÃ©-scrapado para isolar testes de LLM.
    """
    
    # Amostras de conteÃºdo para teste (scraped previamente)
    TEST_CONTENT = {
        "small": [
            # 50 conteÃºdos < 10k tokens
        ],
        "medium": [
            # 100 conteÃºdos 10k-50k tokens
        ],
        "large": [
            # 100 conteÃºdos 50k-200k tokens
        ],
        "very_large": [
            # 50 conteÃºdos > 200k tokens
        ]
    }
    
    async def run_full_suite(self) -> LLMTestReport:
        """
        Executa todos os testes e gera relatÃ³rio.
        
        MÃ©tricas coletadas:
        - provider_usado
        - tempo_total
        - tokens_input
        - tokens_output
        - chunks_processados
        - campos_extraidos
        - qualidade_extracao (score 0-100)
        - rate_limits_encontrados
        - retries_necessarios
        - sucesso (bool)
        - erro (se houver)
        """
    
    async def test_provider_isolation(self, provider: str) -> ProviderReport:
        """
        Testa um provedor especÃ­fico isoladamente.
        Ãštil para identificar problemas especÃ­ficos.
        """
    
    async def test_concurrent_load(self, concurrency: int) -> LoadTestReport:
        """
        Testa comportamento sob carga.
        Simula N requisiÃ§Ãµes simultÃ¢neas.
        """
    
    def calculate_extraction_quality(self, profile: CompanyProfile, expected: Dict) -> int:
        """
        Calcula score de qualidade da extraÃ§Ã£o (0-100).
        Compara campos extraÃ­dos com ground truth.
        """
```

#### 4.2.3 Integration Test Suite

```python
# tests/test_integration_suite.py

class IntegrationTestSuite:
    """
    Testes de integraÃ§Ã£o end-to-end.
    Simula fluxo completo de anÃ¡lise de empresa.
    """
    
    TEST_COMPANIES = [
        # 100 empresas com ground truth conhecido
        {
            "nome_fantasia": "Empresa X",
            "razao_social": "Empresa X LTDA",
            "cnpj": "12.345.678/0001-90",
            "site_esperado": "https://empresax.com.br",
            "campos_esperados": {
                "identity.company_name": "Empresa X",
                "classification.industry": "Tecnologia",
                # ...
            }
        }
    ]
    
    async def run_full_integration(self) -> IntegrationReport:
        """
        Executa fluxo completo para cada empresa.
        
        MÃ©tricas:
        - tempo_total (deve ser < 90s)
        - discovery_sucesso
        - scraper_sucesso
        - llm_sucesso
        - perfil_completo
        - campos_corretos (comparado com ground truth)
        """
```

#### 4.2.4 ğŸ† STRESS TEST (CritÃ©rio de AprovaÃ§Ã£o Final)

```python
# tests/test_stress_500.py

class StressTest500:
    """
    TESTE DEFINITIVO DE APROVAÃ‡ÃƒO DO SISTEMA.
    Processa 500 empresas em paralelo e valida mÃ©tricas.
    
    Este teste DEVE passar para o sistema ser considerado pronto para produÃ§Ã£o.
    """
    
    # Lista de 500 empresas brasileiras reais (CNPJs vÃ¡lidos)
    # Fonte: Base de dados de empresas ativas
    TEST_COMPANIES_500 = "tests/data/empresas_500.json"
    
    # ConfiguraÃ§Ã£o do teste
    CONFIG = {
        "total_empresas": 500,
        "timeout_por_empresa": 90,  # segundos
        "workers_paralelos": 50,    # RequisiÃ§Ãµes simultÃ¢neas
        "timeout_global": 3600,     # 1 hora mÃ¡ximo para todo o teste
    }
    
    # CritÃ©rios de APROVAÃ‡ÃƒO (todos devem ser atendidos)
    CRITERIOS_APROVACAO = {
        "tempo_medio_max": 90,        # segundos (apenas empresas com site)
        "taxa_sucesso_min": 0.90,     # 90% das empresas com site encontrado
        "completude_perfil_min": 0.85, # 85% dos campos obrigatÃ³rios
        "crashes_max": 0,              # Zero crashes
        "memory_leak": False,          # Sem vazamento de memÃ³ria
    }
    
    async def run_stress_test(self) -> StressTestReport:
        """
        Executa o stress test completo.
        
        Fluxo:
        1. Carrega 500 empresas
        2. Processa em paralelo (50 workers)
        3. Coleta mÃ©tricas de cada empresa
        4. Separa: com_site vs sem_site
        5. Calcula mÃ©tricas apenas das com_site
        6. Valida contra critÃ©rios de aprovaÃ§Ã£o
        
        Returns:
            StressTestReport com resultado APROVADO/REPROVADO
        """
    
    def calcular_metricas(self, resultados: List[EmpresaResult]) -> Metricas:
        """
        Calcula mÃ©tricas APENAS das empresas com site encontrado.
        
        Empresas descartadas (NÃƒO contam):
        - site_nao_encontrado: Discovery nÃ£o achou site
        - site_fora_do_ar: Site existe mas nÃ£o responde
        - site_bloqueado: Acesso negado geograficamente
        """
        
        # Filtrar apenas empresas com site encontrado
        com_site = [r for r in resultados if r.site_encontrado and r.site_acessivel]
        
        # Calcular mÃ©tricas
        tempo_medio = sum(r.tempo_total for r in com_site) / len(com_site)
        taxa_sucesso = sum(1 for r in com_site if r.perfil_gerado) / len(com_site)
        completude_media = sum(r.completude for r in com_site) / len(com_site)
        
        return Metricas(
            total_empresas=len(resultados),
            com_site=len(com_site),
            sem_site=len(resultados) - len(com_site),
            tempo_medio=tempo_medio,
            taxa_sucesso=taxa_sucesso,
            completude_media=completude_media
        )
    
    def calcular_completude(self, perfil: CompanyProfile) -> float:
        """
        Calcula completude do perfil (0.0 a 1.0).
        
        SeÃ§Ãµes e pesos:
        - Identity (company_name, description): 25%
        - Classification (industry, business_model): 15%
        - Offerings (products OU services â‰¥3): 25%
        - Contact (email/telefone, website): 20%
        - Reputation (certifications/partnerships/clients): 15%
        """
        score = 0.0
        
        # Identity (25%)
        if perfil.identity.company_name and perfil.identity.description:
            score += 0.25
        
        # Classification (15%)
        if perfil.classification.industry and perfil.classification.business_model:
            score += 0.15
        
        # Offerings (25%)
        produtos = len(perfil.offerings.products) if perfil.offerings.products else 0
        servicos = len(perfil.offerings.services) if perfil.offerings.services else 0
        if produtos >= 3 or servicos >= 3:
            score += 0.25
        
        # Contact (20%)
        tem_contato = (
            (perfil.contact.emails and len(perfil.contact.emails) > 0) or
            (perfil.contact.phones and len(perfil.contact.phones) > 0)
        )
        if tem_contato and perfil.contact.website_url:
            score += 0.20
        
        # Reputation (15%)
        tem_reputacao = (
            (perfil.reputation.certifications and len(perfil.reputation.certifications) > 0) or
            (perfil.reputation.partnerships and len(perfil.reputation.partnerships) > 0) or
            (perfil.reputation.client_list and len(perfil.reputation.client_list) > 0)
        )
        if tem_reputacao:
            score += 0.15
        
        return score
    
    def validar_aprovacao(self, metricas: Metricas) -> Tuple[bool, List[str]]:
        """
        Valida se o teste passou nos critÃ©rios de aprovaÃ§Ã£o.
        
        Returns:
            (aprovado: bool, motivos_reprovacao: List[str])
        """
        motivos = []
        
        if metricas.tempo_medio > self.CRITERIOS_APROVACAO["tempo_medio_max"]:
            motivos.append(f"Tempo mÃ©dio {metricas.tempo_medio:.1f}s > {self.CRITERIOS_APROVACAO['tempo_medio_max']}s")
        
        if metricas.taxa_sucesso < self.CRITERIOS_APROVACAO["taxa_sucesso_min"]:
            motivos.append(f"Taxa sucesso {metricas.taxa_sucesso:.1%} < {self.CRITERIOS_APROVACAO['taxa_sucesso_min']:.0%}")
        
        if metricas.completude_media < self.CRITERIOS_APROVACAO["completude_perfil_min"]:
            motivos.append(f"Completude {metricas.completude_media:.1%} < {self.CRITERIOS_APROVACAO['completude_perfil_min']:.0%}")
        
        return (len(motivos) == 0, motivos)
    
    def gerar_relatorio(self, metricas: Metricas, aprovado: bool, motivos: List[str]) -> str:
        """
        Gera relatÃ³rio detalhado do stress test.
        """
        return f"""
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘                    RELATÃ“RIO DO STRESS TEST - 500 EMPRESAS                   â•‘
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘                                                                              â•‘
        â•‘  RESULTADO: {'âœ… APROVADO' if aprovado else 'âŒ REPROVADO'}                   â•‘
        â•‘                                                                              â•‘
        â•‘  ğŸ“Š MÃ‰TRICAS:                                                                â•‘
        â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                â•‘
        â•‘  Total de empresas:     {metricas.total_empresas}                            â•‘
        â•‘  Com site encontrado:   {metricas.com_site} ({metricas.com_site/metricas.total_empresas:.1%})â•‘
        â•‘  Sem site (descartadas):{metricas.sem_site}                                  â•‘
        â•‘                                                                              â•‘
        â•‘  Tempo mÃ©dio:           {metricas.tempo_medio:.1f}s (meta: â‰¤90s)             â•‘
        â•‘  Taxa de sucesso:       {metricas.taxa_sucesso:.1%} (meta: â‰¥90%)             â•‘
        â•‘  Completude mÃ©dia:      {metricas.completude_media:.1%} (meta: â‰¥85%)         â•‘
        â•‘                                                                              â•‘
        {'â•‘  âŒ MOTIVOS DA REPROVAÃ‡ÃƒO:' if motivos else ''}
        {''.join(f'â•‘     â€¢ {m}' for m in motivos)}
        â•‘                                                                              â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
```

### 4.3 Estrutura de RelatÃ³rios

```
tests/
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ 2025-12-05_full_suite.json
â”‚   â”‚   â”œâ”€â”€ 2025-12-05_cloudflare_only.json
â”‚   â”‚   â””â”€â”€ baseline.json
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ 2025-12-05_full_suite.json
â”‚   â”‚   â”œâ”€â”€ 2025-12-05_google_gemini.json
â”‚   â”‚   â””â”€â”€ baseline.json
â”‚   â””â”€â”€ integration/
â”‚       â”œâ”€â”€ 2025-12-05_full_integration.json
â”‚       â””â”€â”€ sla_compliance.json
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ scraped_content/
â”‚   â”‚   â”œâ”€â”€ small/
â”‚   â”‚   â”œâ”€â”€ medium/
â”‚   â”‚   â””â”€â”€ large/
â”‚   â””â”€â”€ expected_profiles/
â”‚       â””â”€â”€ company_x.json
â””â”€â”€ data/
    â”œâ”€â”€ test_sites.json
    â””â”€â”€ test_companies.json
```

---

## ğŸ“‹ Plano de ImplementaÃ§Ã£o

### Fase 1: FundaÃ§Ã£o (Semana 1-2)

| Task | Prioridade | Estimativa | ResponsÃ¡vel |
|------|------------|------------|-------------|
| Implementar SiteAnalyzer | Alta | 3 dias | - |
| Implementar ProtectionDetector | Alta | 2 dias | - |
| Adicionar OpenRouter ao LLM_BALANCER | Alta | 1 dia | - |
| Implementar FailureTracker | MÃ©dia | 2 dias | - |
| Criar estrutura de testes | MÃ©dia | 2 dias | - |

### Fase 2: Scraper Adaptativo (Semana 3-4)

| Task | Prioridade | Estimativa | ResponsÃ¡vel |
|------|------------|------------|-------------|
| Implementar StrategySelector | Alta | 2 dias | - |
| Implementar Parallel URL Prober | Alta | 1 dia | - |
| Refatorar scrape_url para usar estratÃ©gias | Alta | 3 dias | - |
| Implementar fallback em cascata | Alta | 2 dias | - |
| Criar Scraper Test Suite | MÃ©dia | 2 dias | - |

### Fase 3: LLM Manager v2.0 (Semana 5-6)

| Task | Prioridade | Estimativa | ResponsÃ¡vel |
|------|------------|------------|-------------|
| Implementar LLMQueueManager | Alta | 3 dias | - |
| Implementar AdaptiveTimeout | MÃ©dia | 1 dia | - |
| Refatorar LLMHealthMonitor | Alta | 2 dias | - |
| Ajustar semÃ¡foros e rate limits | Alta | 1 dia | - |
| Criar LLM Test Suite | MÃ©dia | 2 dias | - |

### Fase 4: Learning Engine (Semana 7-8)

| Task | Prioridade | Estimativa | ResponsÃ¡vel |
|------|------------|------------|-------------|
| Implementar PatternAnalyzer | MÃ©dia | 3 dias | - |
| Implementar ConfigOptimizer | MÃ©dia | 2 dias | - |
| Implementar SiteKnowledgeBase | MÃ©dia | 2 dias | - |
| Integrar Learning Engine ao fluxo | MÃ©dia | 2 dias | - |
| Criar Integration Test Suite | MÃ©dia | 1 dia | - |

### Fase 5: ValidaÃ§Ã£o e Ajustes (Semana 9-10)

| Task | Prioridade | Estimativa | ResponsÃ¡vel |
|------|------------|------------|-------------|
| Preparar dataset 500 empresas para stress test | Alta | 1 dia | - |
| Executar stress test inicial | Alta | 1 dia | - |
| Analisar falhas e gargalos | Alta | 2 dias | - |
| Ajustar configuraÃ§Ãµes baseado em resultados | Alta | 2 dias | - |
| Corrigir bugs identificados | Alta | 2 dias | - |
| Re-executar stress test atÃ© aprovaÃ§Ã£o | Alta | 2 dias | - |

### Fase 6: AprovaÃ§Ã£o Final (Semana 11)

| Task | Prioridade | Estimativa | ResponsÃ¡vel |
|------|------------|------------|-------------|
| **Executar STRESS TEST 500** | **CRÃTICA** | 1 dia | - |
| Validar mÃ©tricas contra critÃ©rios | Alta | 0.5 dia | - |
| Gerar relatÃ³rio de aprovaÃ§Ã£o | Alta | 0.5 dia | - |
| Preparar deploy para produÃ§Ã£o | Alta | 1 dia | - |
| Monitoramento pÃ³s-deploy | Alta | 2 dias | - |

**âš ï¸ GATE DE APROVAÃ‡ÃƒO:** O sistema SÃ“ serÃ¡ liberado para produÃ§Ã£o apÃ³s passar no Stress Test 500.

---

## ğŸ“Š MÃ©tricas de Sucesso

### ğŸ† KPIs do Stress Test (CritÃ©rio de AprovaÃ§Ã£o)

| MÃ©trica | Meta | DescriÃ§Ã£o |
|---------|------|-----------|
| **Empresas processadas** | 500 | Em paralelo, simultaneamente |
| **Tempo mÃ©dio** | â‰¤ 90s | Apenas empresas com site encontrado |
| **Taxa de sucesso** | â‰¥ 90% | Das empresas com site encontrado |
| **Completude do perfil** | â‰¥ 85% | Campos obrigatÃ³rios preenchidos |
| **Estabilidade** | 100% | Zero crashes durante execuÃ§Ã£o |

### ğŸ“‹ DefiniÃ§Ã£o de Completude do Perfil

Um perfil Ã© considerado **COMPLETO** quando possui:

| SeÃ§Ã£o | Campos ObrigatÃ³rios | Peso |
|-------|---------------------|------|
| **Identity** | company_name, description | 25% |
| **Classification** | industry, business_model | 15% |
| **Offerings** | products OU services (â‰¥3 itens) | 25% |
| **Contact** | â‰¥1 email OU telefone, website_url | 20% |
| **Reputation** | â‰¥1 de: certifications, partnerships, client_list | 15% |

**FÃ³rmula de Completude:**
```
completude = (seÃ§Ãµes_completas / 5) * 100
perfil_aprovado = completude >= 85%
```

### KPIs SecundÃ¡rios (Monitoramento)

| MÃ©trica | Atual | Meta | MÃ©todo de MediÃ§Ã£o |
|---------|-------|------|-------------------|
| Taxa de Sucesso Geral | ~65% | â‰¥90% | (sucessos / tentativas) * 100 |
| Tempo MÃ©dio de Processamento | ~45s | â‰¤90s | MÃ©dia de tempo por empresa |
| Taxa de Timeout | 19.2% | â‰¤5% | Timeouts / Total |
| Taxa de Rate Limit | ~15% | â‰¤3% | Rate limits / Total LLM calls |
| Taxa de Discovery | ~80% | â‰¥85% | Sites encontrados / Total empresas |

### KPIs por MÃ³dulo

#### Scraper
| MÃ©trica | Atual | Meta |
|---------|-------|------|
| Sites com Cloudflare | 25% falha | â‰¤15% falha |
| Sites estÃ¡ticos | 5% falha | â‰¤2% falha |
| Tempo Main Page | ~5s | â‰¤5s |
| Tempo Subpages (30 pÃ¡ginas) | ~20s | â‰¤25s |
| ConteÃºdo extraÃ­do | ~50k chars | â‰¥30k chars |

#### LLM
| MÃ©trica | Atual | Meta |
|---------|-------|------|
| Taxa de Sucesso Google | ~85% | â‰¥95% |
| Taxa de Sucesso OpenAI | ~80% | â‰¥90% |
| LatÃªncia MÃ©dia por Chunk | ~15s | â‰¤20s |
| Retries NecessÃ¡rios | ~30% | â‰¤15% |

### âš ï¸ Regras de Qualidade (INVIOLÃVEIS)

Para manter a qualidade dos perfis, as seguintes otimizaÃ§Ãµes sÃ£o **PROIBIDAS**:

| OtimizaÃ§Ã£o Proibida | Motivo |
|---------------------|--------|
| âŒ Reduzir nÃºmero de subpÃ¡ginas | Perde informaÃ§Ãµes de produtos/serviÃ§os |
| âŒ Truncar conteÃºdo antes do LLM | Perde contexto e detalhes |
| âŒ Simplificar prompts do LLM | Reduz precisÃ£o da extraÃ§Ã£o |
| âŒ Pular seÃ§Ãµes do perfil | Perfil incompleto |
| âŒ Usar modelos LLM menores/piores | Menor qualidade de extraÃ§Ã£o |
| âŒ Reduzir timeout de scraping | Perde sites lentos mas vÃ¡lidos |

**OtimizaÃ§Ãµes PERMITIDAS:**
- âœ… Paralelismo (mais requisiÃ§Ãµes simultÃ¢neas)
- âœ… Caching de resultados
- âœ… Melhor seleÃ§Ã£o de links (priorizaÃ§Ã£o inteligente)
- âœ… Retry automÃ¡tico com fallback
- âœ… Load balancing entre provedores LLM

---

## ğŸ” ConsideraÃ§Ãµes de SeguranÃ§a

1. **API Keys**: Nunca commitar em cÃ³digo. Usar variÃ¡veis de ambiente.
2. **Rate Limiting**: Implementar rate limiting na API para evitar abuse.
3. **Proxy**: Rotacionar IPs para evitar bloqueios.
4. **Dados SensÃ­veis**: NÃ£o logar conteÃºdo de sites ou respostas de LLM em produÃ§Ã£o.
5. **HTTPS**: Sempre usar HTTPS para conexÃµes externas.

---

## ğŸ“ Changelog

### v2.0 (Proposta)
- [ ] Scraper Adaptativo com estratÃ©gias leves (curl-based)
- [ ] LLM Manager com queue e rate limiting real
- [ ] Learning Engine para auto-otimizaÃ§Ã£o
- [ ] Test Suites automatizadas
- [ ] **NOVO**: Stress Test 500 empresas como critÃ©rio de aprovaÃ§Ã£o
- [ ] **NOVO**: MÃ©tricas de completude de perfil bem definidas
- [ ] **NOVO**: Regras de qualidade inviolÃ¡veis
- [ ] **NOVO**: Arquitetura Multi-Agente Sequencial (inspirado Fire-Enrich)
- [ ] **NOVO**: OpenRouter como provider de LLM com fallback automÃ¡tico
- [ ] **NOVO**: Sistema de semÃ¡foros granulares por recurso
- [ ] **NOVO**: ValidaÃ§Ã£o de schema Pydantic por agente
- [ ] **NOVO**: Tracking de rate limits via headers HTTP
- [ ] **REMOVIDO**: MÃ³dulo de extraÃ§Ã£o de documentos (PDFs, DOCs) - simplificaÃ§Ã£o do fluxo
- [ ] **REMOVIDO**: Playwright/Headless browsers - alto consumo de memÃ³ria

### v1.0 (Atual)
- [x] Scraper bÃ¡sico com curl_cffi
- [x] LLM com round-robin simples
- [x] Circuit breaker bÃ¡sico
- [x] Proxy rotation
- [x] ExtraÃ§Ã£o de PDFs (serÃ¡ removido na v2.0)

---

## ğŸ“š ReferÃªncias

- [curl_cffi Documentation](https://github.com/yifeikong/curl_cffi)
- [OpenRouter API](https://openrouter.ai/docs)
- [Google Gemini API](https://ai.google.dev/docs)
- [Cloudflare Bot Management](https://developers.cloudflare.com/bots/)

---

## ğŸ”¬ AnÃ¡lise de Projetos Similares (Pesquisa GitHub/Web)

### Projetos Analisados

| Projeto | Stars | DescriÃ§Ã£o | RelevÃ¢ncia |
|---------|-------|-----------|------------|
| **ScrapeGraphAI** | 21.9k â­ | Scraper baseado em LLM com pipelines em grafos | Alta |
| **Fire-Enrich** | 1k â­ | Enriquecimento de dados de empresas multi-agente | Muito Alta |
| **Firecrawl** | 50k+ â­ | API de scraping para IA | Alta |
| **BrightData Company Enrichment** | 3 â­ | Enriquecimento de dados com Bright Data API | MÃ©dia |

### ğŸ”¥ Insights do Fire-Enrich (Firecrawl)

O projeto **fire-enrich** Ã© o mais similar ao nosso caso de uso. Sua arquitetura de **agentes sequenciais** Ã© muito relevante:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ARQUITETURA MULTI-AGENTE (Fire-Enrich)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  Fase 1: Discovery Agent â”€â”€â–¶ Encontra empresa e website base               â”‚
â”‚              â”‚                                                             â”‚
â”‚              â–¼                                                             â”‚
â”‚  Fase 2: Company Profile Agent â”€â”€â–¶ Industry, business model                â”‚
â”‚              â”‚              (usa contexto da Fase 1)                       â”‚
â”‚              â–¼                                                             â”‚
â”‚  Fase 3: Financial Intel Agent â”€â”€â–¶ Funding, investors                      â”‚
â”‚              â”‚              (usa contexto das Fases 1-2)                   â”‚
â”‚              â–¼                                                             â”‚
â”‚  Fase 4: Tech Stack Agent â”€â”€â–¶ Tecnologias utilizadas                       â”‚
â”‚              â”‚              (usa contexto das Fases 1-3)                   â”‚
â”‚              â–¼                                                             â”‚
â”‚  Fase 5: General Agent â”€â”€â–¶ Campos customizados                             â”‚
â”‚              â”‚              (usa todo o contexto)                          â”‚
â”‚              â–¼                                                             â”‚
â”‚  SÃ­ntese Final: GPT-4o â”€â”€â–¶ Combina todos os dados, resolve conflitos       â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**LiÃ§Ãµes AplicÃ¡veis:**
1. âœ… **ExecuÃ§Ã£o sequencial de agentes** - Cada fase constrÃ³i contexto para a prÃ³xima
2. âœ… **Buscas paralelas DENTRO de cada fase** - 3+ buscas simultÃ¢neas por agente
3. âœ… **Schemas type-safe com Zod** - ValidaÃ§Ã£o de dados em cada etapa
4. âœ… **SÃ­ntese final com LLM** - ResoluÃ§Ã£o de conflitos entre fontes

### ğŸ•·ï¸ Insights do ScrapeGraphAI (21.9k stars)

```python
# Arquitetura de Pipelines do ScrapeGraphAI
Pipelines disponÃ­veis:
â”œâ”€â”€ SmartScraperGraph      # Scraper de pÃ¡gina Ãºnica
â”œâ”€â”€ SearchGraph            # Multi-pÃ¡gina via busca
â”œâ”€â”€ SmartScraperMultiGraph # MÃºltiplas pÃ¡ginas em paralelo
â”œâ”€â”€ ScriptCreatorGraph     # Gera scripts de extraÃ§Ã£o
â””â”€â”€ SpeechGraph            # Extrai e gera Ã¡udio

# ConfiguraÃ§Ã£o de timeout (implementado recentemente)
graph_config = {
    "llm": {...},
    "verbose": True,
    "headless": False,
    "node_config": {
        "timeout": 30  # Timeout configurÃ¡vel por nÃ³!
    }
}
```

**LiÃ§Ãµes AplicÃ¡veis:**
1. âœ… **Timeout por operaÃ§Ã£o** - NÃ£o apenas timeout global
2. âœ… **Suporte multi-LLM** - Ollama, OpenAI, Groq, Azure, Gemini
3. âœ… **Pipeline graph-based** - Permite reuso e composiÃ§Ã£o
4. âœ… **Telemetria built-in** - MÃ©tricas de uso anÃ´nimas

### ğŸŒ Insights do OpenRouter (API de LLM)

OpenRouter oferece funcionalidades que devemos considerar:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OPENROUTER - FUNCIONALIDADES CHAVE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  ğŸ”„ Model Fallbacks (AutomÃ¡tico)                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  â€¢ Qualquer erro pode triggar fallback: rate limit, context length,        â”‚
â”‚    moderation, timeout                                                     â”‚
â”‚  â€¢ ConfiguraÃ§Ã£o simples via header: X-Fallback-Models                      â”‚
â”‚                                                                            â”‚
â”‚  ğŸ“Š Rate Limits                                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                          â”‚
â”‚  â€¢ Free tier: 20 req/min, 50-1000 req/day                                  â”‚
â”‚  â€¢ Paid tier: Significativamente maior                                     â”‚
â”‚  â€¢ Headers de resposta incluem: X-RateLimit-Remaining, X-RateLimit-Reset   â”‚
â”‚                                                                            â”‚
â”‚  ğŸ§­ Smart Routing                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                            â”‚
â”‚  â€¢ Rota automÃ¡tica para provider mais rÃ¡pido/barato                        â”‚
â”‚  â€¢ Fallback automÃ¡tico quando providers ficam down                         â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**IntegraÃ§Ã£o Proposta:**
```python
# OpenRouter como provider adicional
OPENROUTER_CONFIG = {
    "api_key": "sk-or-v1-xxx",
    "base_url": "https://openrouter.ai/api/v1",
    "models": [
        "google/gemini-2.0-flash-exp:free",  # Fallback gratuito
        "anthropic/claude-3.5-sonnet",       # Alta qualidade
        "openai/gpt-4o-mini",                # RÃ¡pido e barato
    ],
    "fallback_enabled": True,
    "headers": {
        "HTTP-Referer": "https://nossa-api.com",  # ObrigatÃ³rio
        "X-Title": "Company Profile Builder"
    }
}
```

### ğŸ”§ Melhores PrÃ¡ticas de Asyncio para Alto Volume

```python
# PadrÃ£o recomendado para 500 requisiÃ§Ãµes paralelas
import asyncio
from asyncio import Semaphore

class HighThroughputScraper:
    def __init__(self):
        # SemÃ¡foros por tipo de recurso
        self.scrape_semaphore = Semaphore(50)   # 50 scrapes simultÃ¢neos
        self.llm_semaphore = Semaphore(10)       # 10 LLM calls simultÃ¢neos
        self.proxy_semaphore = Semaphore(100)    # 100 conexÃµes proxy
        
        # Rate limiting com token bucket
        self.tokens = asyncio.Queue(maxsize=100)
        
    async def process_with_rate_limit(self, func, *args):
        """Controle de taxa com semÃ¡foro + token bucket"""
        await self.tokens.get()  # Aguarda token disponÃ­vel
        async with self.scrape_semaphore:
            try:
                return await asyncio.wait_for(func(*args), timeout=30)
            finally:
                # RepÃµe token apÃ³s cooldown
                asyncio.create_task(self._replenish_token(0.1))
    
    async def _replenish_token(self, delay):
        await asyncio.sleep(delay)
        await self.tokens.put(True)
```

**PadrÃµes Identificados:**
1. âœ… **Semaphores por recurso** - Limites diferentes para scraping vs LLM
2. âœ… **Token bucket** - Rate limiting suave, nÃ£o hard limit
3. âœ… **Timeout por operaÃ§Ã£o** - `asyncio.wait_for()` em cada chamada
4. âœ… **Replenish assÃ­ncrono** - NÃ£o bloqueia enquanto repÃµe tokens

---

## ğŸš€ Melhorias Incorporadas ao PRD (baseado na pesquisa)

### 1. Arquitetura Multi-Agente Sequencial (inspirado Fire-Enrich)

**Proposta:** Reorganizar o fluxo de LLM em agentes especializados:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FLUXO DE AGENTES PARA CONSTRUÃ‡ÃƒO DE PERFIL                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚  ğŸ” Agente 1: Discovery                                                    â”‚
â”‚     Input: Nome empresa + CNPJ + CNAE                                      â”‚
â”‚     Output: URL do site oficial, nome confirmado                           â”‚
â”‚     Buscas paralelas: 3 queries diferentes no Google                       â”‚
â”‚                                                                            â”‚
â”‚  ğŸ“„ Agente 2: Content Scraper                                              â”‚
â”‚     Input: URL do site + contexto do Agente 1                              â”‚
â”‚     Output: ConteÃºdo HTML de atÃ© 30 pÃ¡ginas                                â”‚
â”‚     Buscas paralelas: Main page + subpÃ¡ginas priorizadas                   â”‚
â”‚                                                                            â”‚
â”‚  ğŸ¢ Agente 3: Identity & Classification                                    â”‚
â”‚     Input: ConteÃºdo scraped + contexto anterior                            â”‚
â”‚     Output: company_name, description, industry, business_model            â”‚
â”‚     Schema: IdentitySchema (validado com Pydantic)                         â”‚
â”‚                                                                            â”‚
â”‚  ğŸ“¦ Agente 4: Products & Services                                          â”‚
â”‚     Input: ConteÃºdo + Identity (para contexto)                             â”‚
â”‚     Output: products[], services[], key_features[]                         â”‚
â”‚     Schema: OfferingsSchema                                                â”‚
â”‚                                                                            â”‚
â”‚  ğŸ“ Agente 5: Contact & Reputation                                         â”‚
â”‚     Input: ConteÃºdo + tudo anterior                                        â”‚
â”‚     Output: emails[], phones[], certifications[], partnerships[]           â”‚
â”‚     Schema: ContactSchema + ReputationSchema                               â”‚
â”‚                                                                            â”‚
â”‚  ğŸ”„ Agente 6: Synthesizer                                                  â”‚
â”‚     Input: Outputs de todos os agentes                                     â”‚
â”‚     Output: CompanyProfile completo e validado                             â”‚
â”‚     FunÃ§Ã£o: Resolver conflitos, preencher gaps, validar consistÃªncia       â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. OpenRouter como Provider de Fallback

**ImplementaÃ§Ã£o Proposta:**
```python
LLM_PROVIDERS = {
    "primary": {
        "google": {"model": "gemini-2.0-flash-exp", "priority": 1},
        "openai": {"model": "gpt-4o-mini", "priority": 2},
    },
    "fallback": {
        "openrouter": {
            "models": [
                "google/gemini-2.0-flash-exp:free",
                "anthropic/claude-3.5-haiku",
                "openai/gpt-4o-mini",
            ],
            "auto_fallback": True,
            "priority": 3
        }
    }
}
```

### 3. Sistema de SemÃ¡foros Granulares

**Proposta:**
```python
SEMAPHORE_CONFIG = {
    # Scraping
    "main_page_scrape": 100,      # 100 main pages em paralelo
    "subpage_scrape": 200,        # 200 subpÃ¡ginas em paralelo
    "proxy_connections": 150,     # 150 conexÃµes proxy simultÃ¢neas
    
    # LLM
    "llm_google": 15,             # 15 chamadas Google simultÃ¢neas
    "llm_openai": 10,             # 10 chamadas OpenAI simultÃ¢neas
    "llm_openrouter": 20,         # 20 chamadas OpenRouter simultÃ¢neas
    "llm_global": 40,             # Total mÃ¡ximo de chamadas LLM
    
    # Discovery
    "serper_search": 20,          # 20 buscas Serper simultÃ¢neas
}
```

### 4. ValidaÃ§Ã£o de Schema por Agente (inspirado ScrapeGraphAI)

**Proposta:**
```python
from pydantic import BaseModel, validator

class IdentitySchema(BaseModel):
    company_name: str
    description: str | None
    industry: str | None
    business_model: str | None
    
    @validator('company_name')
    def name_not_empty(cls, v):
        if not v or len(v.strip()) < 2:
            raise ValueError('Nome da empresa invÃ¡lido')
        return v.strip()

class OfferingsSchema(BaseModel):
    products: list[str] = []
    services: list[str] = []
    key_features: list[str] = []
    
    @validator('products', 'services')
    def deduplicate(cls, v):
        return list(set(v))

# ValidaÃ§Ã£o em cada etapa do pipeline
def validate_agent_output(agent_name: str, data: dict) -> bool:
    schemas = {
        "identity": IdentitySchema,
        "offerings": OfferingsSchema,
        # ...
    }
    try:
        schemas[agent_name](**data)
        return True
    except Exception as e:
        logger.warning(f"ValidaÃ§Ã£o falhou para {agent_name}: {e}")
        return False
```

### 5. MÃ©tricas de Headers de Rate Limit (inspirado OpenRouter)

**Proposta:**
```python
async def track_rate_limits(response: httpx.Response, provider: str):
    """Extrai e rastreia headers de rate limit"""
    headers = response.headers
    
    metrics = {
        "remaining": headers.get("X-RateLimit-Remaining"),
        "limit": headers.get("X-RateLimit-Limit"),
        "reset": headers.get("X-RateLimit-Reset"),
        "provider": provider
    }
    
    # Se estiver chegando no limite, reduzir velocidade
    remaining = int(metrics.get("remaining") or 100)
    if remaining < 10:
        logger.warning(f"âš ï¸ {provider}: Apenas {remaining} requests restantes")
        await asyncio.sleep(1)  # Cooldown preventivo
    
    return metrics
```

---

## ğŸ“‹ Checklist de ImplementaÃ§Ã£o (baseado na pesquisa)

### Fase 1: FundaÃ§Ã£o Revisada
- [ ] Implementar sistema de semÃ¡foros granulares
- [ ] Adicionar OpenRouter como provider de fallback
- [ ] Implementar tracking de rate limits via headers
- [ ] Criar schemas Pydantic para cada tipo de dados

### Fase 2: Arquitetura Multi-Agente
- [ ] Refatorar LLM para arquitetura de agentes sequenciais
- [ ] Implementar validaÃ§Ã£o de schema por agente
- [ ] Adicionar contexto compartilhado entre agentes
- [ ] Criar Synthesizer para consolidaÃ§Ã£o final

### Fase 3: OtimizaÃ§Ã£o de Performance
- [ ] Token bucket para rate limiting suave
- [ ] Timeout por operaÃ§Ã£o (nÃ£o apenas global)
- [ ] Buscas paralelas dentro de cada fase
- [ ] Cooldown preventivo baseado em headers

---

*Documento gerado em 2025-12-05. Ãšltima atualizaÃ§Ã£o: 2025-12-05 (AnÃ¡lise de projetos similares: ScrapeGraphAI, Fire-Enrich, OpenRouter + Arquitetura Multi-Agente)*

